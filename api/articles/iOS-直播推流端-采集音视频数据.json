{"title":"iOS 直播推流端:采集音视频数据","uid":"f7d4fe327521718ef855a7b5e57fec96","slug":"iOS-直播推流端-采集音视频数据","date":"2016-09-08T09:40:42.000Z","updated":"2016-09-08T15:29:05.000Z","comments":true,"path":"api/articles/iOS-直播推流端-采集音视频数据.json","keywords":null,"cover":null,"content":"<p>OS上使用AVFoundation.framework框架来调用系统相机并获取视频数据。视频数据可以根据设定的参数，可采集到RGB或YUV数据，一般使用的是GBRA32，420v，420f，下面演示相机的调用和视频数据的获取。<br>a)引入框架的头文件#import &lt;AVFoundation/AVFoundation.h&gt;<br>b)调用的类遵守协议AVCaptureVideoDataOutputSampleBufferDelegate<br>c)声明变量<br>AVCaptureSession            *captureSession;<br>AVCaptureDevice             *captureDevice;<br>AVCaptureDeviceInput        *captureDeviceInput;<br>AVCaptureVideoDataOutput    *captureVdieoDataOutput;<br>d)实现<br>e)demo地址 <a href=\"https://github.com/depthlove/STMCamera\">https://github.com/depthlove/STMCamera</a></p>\n<p>AVFoundation 是 iOS系统上可以捕捉iPhone／iPad／iPod摄像头的一个库，这个库采集输出的是YUV/RGB。跟编码h264没有关系，AVFoundation只是作为一个视频输入源而已，要将它的数据采用编码器编码才能得到h264 数据。具体可参看我的博文《利用FFmpeg+x264将iOS摄像头实时视频流编码为h264文件》<a href=\"http://depthlove.github.io/2015/09/18/use-ffmpeg-and-x264-encode-iOS-camera-video-to-h264/\">http://depthlove.github.io/2015/09/18/use-ffmpeg-and-x264-encode-iOS-camera-video-to-h264/</a> ， 《利用x264将iOS摄像头实时视频流编码为h264文件》<a href=\"http://depthlove.github.io/2015/09/17/use-x264-encode-iOS-camera-video-to-h264/\">http://depthlove.github.io/2015/09/17/use-x264-encode-iOS-camera-video-to-h264/</a> ， 《在iOS上硬编码推流－硬编码h264（四）》<a href=\"http://depthlove.github.io/2016/03/20/hw-encode-and-transfer-in-ios-platform-videotoolbox-encode-h264-part4/\">http://depthlove.github.io/2016/03/20/hw-encode-and-transfer-in-ios-platform-videotoolbox-encode-h264-part4/</a></p>\n<p>AVFoundation: 音视频数据采集需要用AVFoundation框架.</p>\n<p><code>AVCaptureDevice</code>：硬件设备，包括麦克风、摄像头，通过该对象可以设置物理设备的一些属性（例如相机聚焦、白平衡等）</p>\n<p><code>AVCaptureDeviceInput</code>：硬件输入对象，可以根据AVCaptureDevice创建对应的AVCaptureDeviceInput对象，用于管理硬件输入数据。</p>\n<p><code>AVCaptureOutput</code>：硬件输出对象，用于接收各类输出数据，通常使用对应的子类AVCaptureAudioDataOutput（声音数据输出对象）、AVCaptureVideoDataOutput（视频数据输出对象）</p>\n<p><code>AVCaptionConnection</code>:当把一个输入和输出添加到AVCaptureSession之后，AVCaptureSession就会在输入、输出设备之间建立连接,而且通过AVCaptureOutput可以获取这个连接对象。</p>\n<p><code>AVCaptureVideoPreviewLayer</code>:相机拍摄预览图层，能实时查看拍照或视频录制效果，创建该对象需要指定对应的AVCaptureSession对象，因为AVCaptureSession包含视频输入数据，有视频数据才能展示。</p>\n<p>AVCaptureSession: 协调输入与输出之间传输数据</p>\n<p>系统作用：可以操作硬件设备<br>工作原理：让App与系统之间产生一个捕获会话，相当于App与硬件设备有联系了， 我们只需要把硬件输入对象和输出对象添加到会话中，会话就会自动把硬件输入对象和输出产生连接，这样硬件输入与输出设备就能传输音视频数据。</p>\n<p>现实生活场景：租客（输入钱），中介（会话），房东（输出房），租客和房东都在中介登记，中介就会让租客与房东之间产生联系，以后租客就能直接和房东联系了。</p>\n<p>捕获音视频步骤:官方文档</p>\n<p>1.创建AVCaptureSession对象</p>\n<p>2.获取AVCaptureDevicel录像设备（摄像头），录音设备（麦克风），注意不具备输入数据功能,只是用来调节硬件设备的配置。</p>\n<p>3.根据音频/视频硬件设备(AVCaptureDevice)创建音频/视频硬件输入数据对象(AVCaptureDeviceInput)，专门管理数据输入。</p>\n<p>4.创建视频输出数据管理对象（AVCaptureVideoDataOutput），并且设置样品缓存代理(setSampleBufferDelegate)就可以通过它拿到采集到的视频数据</p>\n<p>5.创建音频输出数据管理对象（AVCaptureAudioDataOutput），并且设置样品缓存代理(setSampleBufferDelegate)就可以通过它拿到采集到的音频数据</p>\n<p>6.将数据输入对象AVCaptureDeviceInput、数据输出对象AVCaptureOutput添加到媒体会话管理对象AVCaptureSession中,就会自动让音频输入与输出和视频输入与输出产生连接.</p>\n<p>7.创建视频预览图层AVCaptureVideoPreviewLayer并指定媒体会话，添加图层到显示容器layer中</p>\n<p>8.启动AVCaptureSession，只有开启，才会开始输入到输出数据流传输。</p>\n<pre class=\"line-numbers language-objc\" data-language=\"objc\"><code class=\"language-objc\">\n\n\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n\n\n<pre class=\"line-numbers language-swift\" data-language=\"swift\"><code class=\"language-swift\">\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n","text":"OS上使用AVFoundation.framework框架来调用系统相机并获取视频数据。视频数据可以根据设定的参数，可采集到RGB或YUV数据，一般使用的是GBRA32，420v，420f，下面演示相机的调用和视频数据的获取。a)引入框架的头文件#import &lt;AVFou...","link":"","photos":[],"count_time":{"symbolsCount":"2.3k","symbolsTime":"2 mins."},"categories":[{"name":"音视频开发","slug":"音视频开发","count":6,"path":"api/categories/音视频开发.json"}],"tags":[{"name":"AVCaptureSession","slug":"AVCaptureSession","count":1,"path":"api/tags/AVCaptureSession.json"},{"name":"AVFoundation","slug":"AVFoundation","count":1,"path":"api/tags/AVFoundation.json"},{"name":"直播推流","slug":"直播推流","count":1,"path":"api/tags/直播推流.json"}],"toc":"","author":{"name":"William Xie","slug":"blog-author","avatar":"/img/author.png","link":"/","description":"","socials":{"github":"https://github.com/williamxiewz","twitter":"https://twitter.com/williamxie_wz","stackoverflow":"http://stackoverflow.com/users/4078104/goingxiebin-jobs","wechat":"","qq":"","weibo":"https://weibo.com/u/2281381063","zhihu":"https://www.zhihu.com/people/williamxiewz","csdn":"https://blog.csdn.net/u014222645","juejin":"https://juejin.cn/user/3280598430133277","customs":{}}},"mapped":true,"prev_post":{"title":"iOS 直播推流端: 硬编码视频H.264和音频AAC","uid":"65b1423852a0fa523adf6becd9cc334f","slug":"iOS-直播推流端-硬编码视频H-264和音频AAC","date":"2016-09-08T09:53:14.000Z","updated":"2016-09-10T04:03:36.000Z","comments":true,"path":"api/articles/iOS-直播推流端-硬编码视频H-264和音频AAC.json","keywords":null,"cover":null,"text":"https://zh.wikipedia.org/zh-cn/網路抽象層#NAL_units 公司项目原因，接触了一下视频流H264的编解码知识，之前项目使用的是FFMpeg多媒体库，利用CPU做视频的编码和解码，俗称为软编软解。该方法比较通用，但是占用CPU资源，编解码效率不高...","link":"","photos":[],"count_time":{"symbolsCount":"4.1k","symbolsTime":"4 mins."},"categories":[],"tags":[],"author":{"name":"William Xie","slug":"blog-author","avatar":"/img/author.png","link":"/","description":"","socials":{"github":"https://github.com/williamxiewz","twitter":"https://twitter.com/williamxie_wz","stackoverflow":"http://stackoverflow.com/users/4078104/goingxiebin-jobs","wechat":"","qq":"","weibo":"https://weibo.com/u/2281381063","zhihu":"https://www.zhihu.com/people/williamxiewz","csdn":"https://blog.csdn.net/u014222645","juejin":"https://juejin.cn/user/3280598430133277","customs":{}}}},"next_post":{"title":"音视频编解码中常用的编译脚本","uid":"af194cf772338e5ab2861d3ce9297882","slug":"音视频编解码中常用的编译脚本","date":"2016-09-08T02:24:33.000Z","updated":"2016-09-08T02:25:16.000Z","comments":true,"path":"api/articles/音视频编解码中常用的编译脚本.json","keywords":null,"cover":null,"text":"FFmpegiOS：https://github.com/kewlbear/FFmpeg-iOS-build-scriptx264iOS：https://github.com/kewlbear/x264-iosfdk-aaciOS：https://github.com/veryb...","link":"","photos":[],"count_time":{"symbolsCount":337,"symbolsTime":"1 mins."},"categories":[{"name":"音视频开发","slug":"音视频开发","count":6,"path":"api/categories/音视频开发.json"}],"tags":[],"author":{"name":"William Xie","slug":"blog-author","avatar":"/img/author.png","link":"/","description":"","socials":{"github":"https://github.com/williamxiewz","twitter":"https://twitter.com/williamxie_wz","stackoverflow":"http://stackoverflow.com/users/4078104/goingxiebin-jobs","wechat":"","qq":"","weibo":"https://weibo.com/u/2281381063","zhihu":"https://www.zhihu.com/people/williamxiewz","csdn":"https://blog.csdn.net/u014222645","juejin":"https://juejin.cn/user/3280598430133277","customs":{}}}}}