{"title":"移动端直播应用的开发流程","uid":"d5c815160e8fec6a4b0bd832cd6d3ef9","slug":"移动端直播应用的开发流程","date":"2016-09-07T12:01:52.000Z","updated":"2016-09-08T10:00:56.000Z","comments":true,"path":"api/articles/移动端直播应用的开发流程.json","keywords":null,"cover":null,"content":"<p>#推流端</p>\n<p><code>推流,就是将采集到的音频,视频数据通过流媒体协议发送到流媒体服务器。</code></p>\n<p>##一、选择流媒体协议</p>\n<p>现在直播应用，采用RTMP协议居多，也有部分使用HLS协议。</p>\n<p>采用RTMP协议，就要看下它与流媒体服务器交互的过程，RTMP协议的默认端口是1935，采用TCP协议。并且需要了解FLV的封装格式。</p>\n<p>采用HLS协议，因为涉及到切片，延时会比较大，需要了解TS流。</p>\n<p>##二、采集音视频数据</p>\n<p>做直播，数据的来源不可缺少，就是采集摄像头，麦克风的数据。<br>iOS平台上采集音视频数据，需要使用AVFoundation.Framework框架，从captureSession会话的回调中获取音频,视频数据。</p>\n<p>##三、硬编码,软编码音视频数据</p>\n<p>软编码利用CPU资源来压缩音视频数据，硬编码与之相反。</p>\n<p>软编码的话，现在广泛采用FFmpeg库结合编码库来实现，<code>FFmpeg+X624</code>来编码视频数据YUV/RGB输出H.264数据,<code>FFmpeg+fdk_aac</code>来编码音频数据PCM输出AAC数据。</p>\n<p>硬编码的话,iOS可以使用<code>VideoToolBox.framework</code> 和 <code>AudioToolBox.framework</code>.</p>\n<p>##四、根据所选流媒体协议封包音视频数据</p>\n<p>将音频编码流,视频编码流打包成packet.</p>\n<p>##五、与服务器交互发送封包数据</p>\n<p>根据所选<code>流媒体协议</code>，发送相应指令连接服务器，连接服务器成功后，就可以发送packet数据了。</p>\n<p>#拉流端</p>\n<p><code>拉流,就是从流媒体服务器获取音频,视频数据。</code></p>\n<p>##一、解析协议</p>\n<p>播放器端根据URL解析所用的流媒体协议（RTMP，HLS）。</p>\n<p>##二、解封装</p>\n<p>解封装，就是demux的过程，从容器格式（FLV，TS）中，分离出音视频数据。</p>\n<p>##三、解码</p>\n<p>解码，就是把获取到的数据解压缩，恢复成原始数据。解码就是将H.264变成YUV，AAC变成PCM。</p>\n<p>解码可以使用软解码,硬解码两种方式.</p>\n<p>软解码:</p>\n<ul>\n<li>利用CPU资源去解压缩数据，采用的方式是FFmpeg解码。</li>\n</ul>\n<p>硬解码:</p>\n<ul>\n<li><p>对于iOS平台来说，可以使用<code>VideoToolbox.Framework</code>（该框架只能在iOS 8.0及以上系统使用）硬解码视频数据。</p>\n</li>\n<li><p>Android平台上，可以使用<code>MediaCodec</code>来硬解码视频数据。</p>\n</li>\n</ul>\n<p>##四、渲染数据</p>\n<p>采用<code>OpenGL</code>渲染YUV数据，呈现视频画面。将PCM送入设备的硬件资源播放，产生声音。<br>iOS播放流式音频，使用Audio Queue 的方式，即，利用AudioToolbox.Framework 框架。</p>\n<p>也可以使用Apple 2014年发布的 <code>Metal</code>来渲染 YUV数据.</p>\n<p><a href=\"http://depthlove.github.io/2016/05/09/live-broadcast-development-process/\">原文</a></p>\n","text":"#推流端 推流,就是将采集到的音频,视频数据通过流媒体协议发送到流媒体服务器。 ##一、选择流媒体协议 现在直播应用，采用RTMP协议居多，也有部分使用HLS协议。 采用RTMP协议，就要看下它与流媒体服务器交互的过程，RTMP协议的默认端口是1935，采用TCP协议。并且需要了...","link":"","photos":[],"count_time":{"symbolsCount":"1.1k","symbolsTime":"1 mins."},"categories":[{"name":"音视频开发","slug":"音视频开发","count":7,"path":"api/categories/音视频开发.json"}],"tags":[],"toc":"","author":{"name":"William Xie","slug":"blog-author","avatar":"/img/author.png","link":"/","description":"","socials":{"github":"https://github.com/williamxiewz","twitter":"https://twitter.com/williamxie_wz","stackoverflow":"http://stackoverflow.com/users/4078104/goingxiebin-jobs","wechat":"","qq":"","weibo":"https://weibo.com/u/2281381063","zhihu":"https://www.zhihu.com/people/williamxiewz","csdn":"https://blog.csdn.net/u014222645","juejin":"https://juejin.cn/user/3280598430133277","customs":{}}},"mapped":true,"prev_post":{"title":"使用fdk-aac将iOS麦克风实时音频流编码为aac文件","uid":"09b66e066b45ce5ea1b53698890ec7ad","slug":"使用fdk-aac将iOS麦克风实时音频流编码为aac文件","date":"2016-09-07T16:58:20.000Z","updated":"2016-09-07T16:59:36.000Z","comments":true,"path":"api/articles/使用fdk-aac将iOS麦克风实时音频流编码为aac文件.json","keywords":null,"cover":null,"text":" iOS系统上的音频硬编码器，可实现将pcm音频数据编码为aac格式的数据。但是，对于低码率下的音频编码，就是它的软肋了。通过函数扫描iOS各系统上音频硬编码支持的情况发现，aac-lc编码都是支持的，苹果的官方文档也说的很清楚。对于aac-he-v2编码，iOS现在所有的系统都...","link":"","photos":[],"count_time":{"symbolsCount":952,"symbolsTime":"1 mins."},"categories":[{"name":"音视频开发","slug":"音视频开发","count":7,"path":"api/categories/音视频开发.json"}],"tags":[{"name":"fdk-aac","slug":"fdk-aac","count":1,"path":"api/tags/fdk-aac.json"},{"name":"aac","slug":"aac","count":1,"path":"api/tags/aac.json"}],"author":{"name":"William Xie","slug":"blog-author","avatar":"/img/author.png","link":"/","description":"","socials":{"github":"https://github.com/williamxiewz","twitter":"https://twitter.com/williamxie_wz","stackoverflow":"http://stackoverflow.com/users/4078104/goingxiebin-jobs","wechat":"","qq":"","weibo":"https://weibo.com/u/2281381063","zhihu":"https://www.zhihu.com/people/williamxiewz","csdn":"https://blog.csdn.net/u014222645","juejin":"https://juejin.cn/user/3280598430133277","customs":{}}}},"next_post":{"title":"什么是I帧,P帧,B帧","uid":"99c5f55389acbd9de2b2a8aa78d3843c","slug":"什么是I帧-P帧-B帧","date":"2016-09-07T05:53:44.000Z","updated":"2019-05-14T04:53:25.000Z","comments":true,"path":"api/articles/什么是I帧-P帧-B帧.json","keywords":null,"cover":[],"text":"H.264是新一代的编码标准，以高压缩高质量和支持多种网络的流媒体传输著称，在编码方面，我理解的他的理论依据是： 参照一段时间内图像的统计结果表明，在相邻几幅图像画面中，一般有差别的像素只有10%以内的点,亮度差值变化不超过2%，而色度差值的变化只有1%以内。所以对于一段变化不大...","link":"","photos":[],"count_time":{"symbolsCount":"4.1k","symbolsTime":"4 mins."},"categories":[{"name":"音视频开发","slug":"音视频开发","count":7,"path":"api/categories/音视频开发.json"}],"tags":[{"name":"H.264","slug":"H-264","count":1,"path":"api/tags/H-264.json"}],"author":{"name":"William Xie","slug":"blog-author","avatar":"/img/author.png","link":"/","description":"","socials":{"github":"https://github.com/williamxiewz","twitter":"https://twitter.com/williamxie_wz","stackoverflow":"http://stackoverflow.com/users/4078104/goingxiebin-jobs","wechat":"","qq":"","weibo":"https://weibo.com/u/2281381063","zhihu":"https://www.zhihu.com/people/williamxiewz","csdn":"https://blog.csdn.net/u014222645","juejin":"https://juejin.cn/user/3280598430133277","customs":{}}}}}